============================= test session starts ==============================
platform linux -- Python 3.10.6, pytest-7.2.0, pluggy-1.0.0
rootdir: /root/projects/qcs
collected 12 items / 11 deselected / 1 selected

tst/qdao/engine.py 
::::::::::::::::::Config::::::::::::::::::

NQ::	30
NP::	28
NL::	24

::::::::::::::::::Config::::::::::::::::::

Partial simulation consumes time: 507.45626044273376
F

=================================== FAILURES ===================================
_ TestEngine.test_run_quafu_any_qasm[circuit_n30_m14_s7_e6_pEFGH.qasm-30-28-24-QDAO] _

self = <engine.TestEngine object at 0x7fb0f89a95a0>, nq = '30', np = '28'
nl = '24', mode = 'QDAO', qasm = 'circuit_n30_m14_s7_e6_pEFGH.qasm'

    def test_run_quafu_any_qasm(self, nq, np, nl, mode, qasm):
        """
        Basic test to run random circuits and
        compare performance between
        1. Qdao on top of quafu
        2. Quafu
        """
        NQ, NP, NL = self.get_qdao_params(nq, np, nl)
    
        print("\n::::::::::::::::::Config::::::::::::::::::\n")
        print("NQ::\t{}".format(NQ))
        print("NP::\t{}".format(NP))
        print("NL::\t{}".format(NL))
        print("\n::::::::::::::::::Config::::::::::::::::::\n")
    
        circ = qiskit.circuit.QuantumCircuit.from_qasm_file(QDAO_QASM_DIR + qasm)
        circ = transpile(circ, self._sv_sim)
    
>       self.run_quafu_diff_test(circ, NQ, NP, NL, mode=mode)

tst/qdao/engine.py:342: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tst/qdao/engine.py:261: in run_quafu_diff_test
    engine.run()
qdao/engine.py:170: in run
    self._run(sub_circ)
utils/misc.py:21: in wrapper
    result = func(*args, **kwargs)
qdao/engine.py:115: in _run
    simobj = self._preprocess(sub_circ, ichunk)
utils/misc.py:21: in wrapper
    result = func(*args, **kwargs)
qdao/engine.py:78: in _preprocess
    sv = self._manager.load_sv(sub_circ.real_qubits)
utils/misc.py:21: in wrapper
    result = func(*args, **kwargs)
qdao/manager.py:132: in load_sv
    self._load_single_su(isub, fn)
qdao/manager.py:85: in _load_single_su
    vec = np.load(fn)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

file = 'data/sv16.npy', mmap_mode = None, allow_pickle = False
fix_imports = True, encoding = 'ASCII'

    @set_module('numpy')
    def load(file, mmap_mode=None, allow_pickle=False, fix_imports=True,
             encoding='ASCII'):
        """
        Load arrays or pickled objects from ``.npy``, ``.npz`` or pickled files.
    
        .. warning:: Loading files that contain object arrays uses the ``pickle``
                     module, which is not secure against erroneous or maliciously
                     constructed data. Consider passing ``allow_pickle=False`` to
                     load data that is known not to contain object arrays for the
                     safer handling of untrusted sources.
    
        Parameters
        ----------
        file : file-like object, string, or pathlib.Path
            The file to read. File-like objects must support the
            ``seek()`` and ``read()`` methods and must always
            be opened in binary mode.  Pickled files require that the
            file-like object support the ``readline()`` method as well.
        mmap_mode : {None, 'r+', 'r', 'w+', 'c'}, optional
            If not None, then memory-map the file, using the given mode (see
            `numpy.memmap` for a detailed description of the modes).  A
            memory-mapped array is kept on disk. However, it can be accessed
            and sliced like any ndarray.  Memory mapping is especially useful
            for accessing small fragments of large files without reading the
            entire file into memory.
        allow_pickle : bool, optional
            Allow loading pickled object arrays stored in npy files. Reasons for
            disallowing pickles include security, as loading pickled data can
            execute arbitrary code. If pickles are disallowed, loading object
            arrays will fail. Default: False
    
            .. versionchanged:: 1.16.3
                Made default False in response to CVE-2019-6446.
    
        fix_imports : bool, optional
            Only useful when loading Python 2 generated pickled files on Python 3,
            which includes npy/npz files containing object arrays. If `fix_imports`
            is True, pickle will try to map the old Python 2 names to the new names
            used in Python 3.
        encoding : str, optional
            What encoding to use when reading Python 2 strings. Only useful when
            loading Python 2 generated pickled files in Python 3, which includes
            npy/npz files containing object arrays. Values other than 'latin1',
            'ASCII', and 'bytes' are not allowed, as they can corrupt numerical
            data. Default: 'ASCII'
    
        Returns
        -------
        result : array, tuple, dict, etc.
            Data stored in the file. For ``.npz`` files, the returned instance
            of NpzFile class must be closed to avoid leaking file descriptors.
    
        Raises
        ------
        OSError
            If the input file does not exist or cannot be read.
        UnpicklingError
            If ``allow_pickle=True``, but the file cannot be loaded as a pickle.
        ValueError
            The file contains an object array, but ``allow_pickle=False`` given.
    
        See Also
        --------
        save, savez, savez_compressed, loadtxt
        memmap : Create a memory-map to an array stored in a file on disk.
        lib.format.open_memmap : Create or load a memory-mapped ``.npy`` file.
    
        Notes
        -----
        - If the file contains pickle data, then whatever object is stored
          in the pickle is returned.
        - If the file is a ``.npy`` file, then a single array is returned.
        - If the file is a ``.npz`` file, then a dictionary-like object is
          returned, containing ``{filename: array}`` key-value pairs, one for
          each file in the archive.
        - If the file is a ``.npz`` file, the returned value supports the
          context manager protocol in a similar fashion to the open function::
    
            with load('foo.npz') as data:
                a = data['a']
    
          The underlying file descriptor is closed when exiting the 'with'
          block.
    
        Examples
        --------
        Store data to disk, and load it again:
    
        >>> np.save('/tmp/123', np.array([[1, 2, 3], [4, 5, 6]]))
        >>> np.load('/tmp/123.npy')
        array([[1, 2, 3],
               [4, 5, 6]])
    
        Store compressed data to disk, and load it again:
    
        >>> a=np.array([[1, 2, 3], [4, 5, 6]])
        >>> b=np.array([1, 2])
        >>> np.savez('/tmp/123.npz', a=a, b=b)
        >>> data = np.load('/tmp/123.npz')
        >>> data['a']
        array([[1, 2, 3],
               [4, 5, 6]])
        >>> data['b']
        array([1, 2])
        >>> data.close()
    
        Mem-map the stored array, and then access the second row
        directly from disk:
    
        >>> X = np.load('/tmp/123.npy', mmap_mode='r')
        >>> X[1, :]
        memmap([4, 5, 6])
    
        """
        if encoding not in ('ASCII', 'latin1', 'bytes'):
            # The 'encoding' value for pickle also affects what encoding
            # the serialized binary data of NumPy arrays is loaded
            # in. Pickle does not pass on the encoding information to
            # NumPy. The unpickling code in numpy.core.multiarray is
            # written to assume that unicode data appearing where binary
            # should be is in 'latin1'. 'bytes' is also safe, as is 'ASCII'.
            #
            # Other encoding values can corrupt binary data, and we
            # purposefully disallow them. For the same reason, the errors=
            # argument is not exposed, as values other than 'strict'
            # result can similarly silently corrupt numerical data.
            raise ValueError("encoding must be 'ASCII', 'latin1', or 'bytes'")
    
        pickle_kwargs = dict(encoding=encoding, fix_imports=fix_imports)
    
        with contextlib.ExitStack() as stack:
            if hasattr(file, 'read'):
                fid = file
                own_fid = False
            else:
>               fid = stack.enter_context(open(os_fspath(file), "rb"))
E               FileNotFoundError: [Errno 2] No such file or directory: 'data/sv16.npy'

/root/anaconda3/envs/qcs-noise/lib/python3.10/site-packages/numpy/lib/npyio.py:390: FileNotFoundError
=========================== short test summary info ============================
FAILED tst/qdao/engine.py::TestEngine::test_run_quafu_any_qasm[circuit_n30_m14_s7_e6_pEFGH.qasm-30-28-24-QDAO]
================= 1 failed, 11 deselected in 540.12s (0:09:00) =================
